source(file.path(REGO_HOME, "/src/rfExport.R"))
source(file.path(REGO_HOME, "/src/rfRulesIO.R"))

# Constants
kContinuousSplitTestOps <- c(' < ',' <= ',' > ', ' >= ')

MergeDuplicateTerms <- function(terms)
{
  # Dedupes term list. For computational efficiency reasons, Friedman's implementation
  # keeps rules in their source trees, so duplicates can be present in a RuleFit model.
  #
  # Args:
  #          terms : list of <type, supp|std, coeff, imp, splits|var> tuples,
  #                  as generated by the ReadRules() function
  # Returns:
  #          deduped list.
  CompareCategoricalSplits <- function(s1, s2) {
    stopifnot(s1$type == "categorical" && s2$type == "categorical")
    if (s1$var != s2$var || s1$cond != s2$cond || length(s1$levels) != length(s2$levels)) {
      return(FALSE)
    }
    if (identical(sort(s1$levels), sort(s2$levels)) )  
      return(TRUE)
    else
      return(FALSE)
  }
  
  CompareContinuousSplits <- function(s1, s2) {
    stopifnot(s1$type == "continuous" &&  s2$type == "continuous")
    if (s1$var == s2$var && s1$min == s2$min && s1$max == s2$max) {
      return(TRUE)
    } else {
      return(FALSE)
    }
  }

  CompareSplitLists <- function(l1, l2) {  
    stopifnot(length(l1) == length(l2))
    nSplits <- length(l1)
    bMatched <- rep(FALSE, nSplits)
    for (l1.split in l1) {
      bFoundMatch <- FALSE
      for (i.l2.split in seq.int(1, nSplits, +1)) {
        if (!bMatched[i.l2.split]) {
          l2.split <- l2[[i.l2.split]]
          if (l1.split$type != l2.split$type) {
            next
          }
          if (l1.split$type == "continuous") {
            if (CompareContinuousSplits(l1.split, l2.split)) {
              bFoundMatch <- TRUE
              bMatched[i.l2.split] <- TRUE
              break
            }
          } else {
            if (CompareCategoricalSplits(l1.split, l2.split)) {
              bFoundMatch <- TRUE
              bMatched[i.l2.split] <- TRUE
              break
            }
          }
        }
      }
      if (!bFoundMatch) {
        return(FALSE)
      }
    }
    return(TRUE)
  }
  
  CompareTerms <- function(t1, t2) {
    if (t1$type != t2$type) {
      return(FALSE)
    }
    if (t1$type == "linear" && t2$type == "linear") {
      if (t1$var == t2$var)
        return(TRUE)
      else
        return(FALSE)
    }
    if (t1$type != "split" || t2$type != "split") {
      error(logger, paste("CompareTerms: unexpected term type: '", t1$type, "', '", t2$type, "'"))
    }
    if (length(t1$splits) != length(t2$splits)) {
      return(FALSE)
    }
    return(CompareSplitLists(t1$splits, t2$splits))
  }
  
  # -----------------------------------------------------------------------
  stopifnot(length(terms) > 1)
  
  nTerms <- length(terms)
  terms.dedup <- list()
  bIsDup <- rep(FALSE, nTerms)
  iTermOut <- 1
  iTermIn <- 1
  repeat {
    while (iTermIn <= nTerms && bIsDup[iTermIn]) {
      iTermIn <- iTermIn + 1
    }
    if (iTermIn > nTerms) {
      break
    } else if (iTermIn == nTerms) {
      terms.dedup[[iTermOut]] <- terms[[iTermIn]]
      break
    } else {
      term <- terms[[iTermIn]]
      for (iTerm in seq.int(iTermIn+1, nTerms, +1)) {
        if (!bIsDup[iTerm]) {
          termNext <- terms[[iTerm]]
          if (CompareTerms(term, termNext)) {
            term$coeff <- term$coeff + termNext$coeff
            dbg(logger, paste("MergeDuplicateTerms: merging term", iTermIn, ">>", 
                    ifelse(term$type == kRuleTypeLinear, LinearRule2Char(term), SplitRule2Char(term, NULL)), 
                    "<< and term", iTerm, ">>", 
                    ifelse(termNext$type == kRuleTypeLinear, LinearRule2Char(termNext), SplitRule2Char(termNext, NULL)), 
                    "<<"))
            bIsDup[iTerm] <- TRUE
          }
        }
      }
      terms.dedup[[iTermOut]] <- term
      iTermOut <- iTermOut + 1
      iTermIn <- iTermIn + 1
    }
  }
  
  return(terms.dedup)
}

ConvertTermsToSQL <- function(terms, db.type, x.levels.fname = "", x.levels.lowcount.fname = "", x.trims = NULL)
{
  # Converts RuleFit terms into a SQL-compatible version.
  #
  # Args:
  #          terms : list of <type, supp|std, coeff, imp, splits|var> tuples,
  #                  as generated by the ReadRules() function
  #        db.type : SQL dialect to use
  # x.levels.fname : (optional) - text file with <var.name, var.levels> pairs
  # x.levels.lowcount.fname: (optional) - text file with <var.name, low-count var.levels> pairs
  #  x.trims.fname : (optional) - text file with <var-name, min, max, mean> tuples.
  #
  # Returns:
  #          data-frame with <type, coeff, rule definition as a SQL-like string> tuples
  ConvertCategoricalSplitTest <- function(split.str)
  {
    # Transforms splits of the form 'x IN ('v1', 'v2', NA, ...)' into sql clause
    # '(x IS NULL OR x IN ('v1', 'v2', ...))' and split 'x NOT IN ('v1', 'v2', NA, ...)' 
    # into sql clause '(x IS NOT NULL AND x NOT IN ('v1', 'v2', ...))'
    stopifnot(grepl(" AND ", split.str) == FALSE)
    stopifnot(grepl(' IN \\( ', split.str))
    
    # Remove leading/trailing white space; split
    split.str <- gsub("^\\s+", '', split.str, perl = TRUE) 
    split.str <- gsub('\\s+$', '', split.str, perl = TRUE) 
    split.parts <- strsplit(split.str, " ")[[1]]
    split.var <- split.parts[1]
    split.op <- split.parts[2]
    
    # Create NULL test string
    if (split.op == "NOT") {
      isNullStr <- paste(split.var, "IS NOT NULL")
      split.op.is.NOT <- TRUE
    } else {
      isNullStr <- paste(split.var, "IS NULL")
      split.op.is.NOT <- FALSE
    }
    
    # Now remove NA from the list of test levels (if present)
    if (grepl('NA,', split.str)) {
      # NA at start, or middle, of value list
      split.str <- gsub('NA,', "", split.str)
      split.str <- paste("(", isNullStr, ifelse(split.op.is.NOT, " AND ", " OR "), split.str, ")", sep = "")
    } else if (grepl(',NA', split.str)) {
      # NA at end of value list
      split.str <- gsub(',NA', "", split.str)
      split.str <- paste("(", isNullStr, ifelse(split.op.is.NOT, " AND ", " OR "), split.str, ")", sep = "")
    } else if (grepl('\\( NA \\)', split.str)) {
      # NA is only element of value list
      split.str <- isNullStr
    } else {
      # NA is not present value list... splits of the form 'x NOT IN ('v1', 'v2', ...)', with
      # vi != NA, need to be converted into sql clause '(x IS NULL OR x NOT IN ('v1', 'v2', ...))'
      if (split.op.is.NOT) {
        split.str <- paste("(", split.var, " IS NULL OR ", split.str, ")", sep = "")
      }
    }
    
    return(split.str)
  }
  
  ConvertContinuousSplitTest <- function(split.str)
  {
    # Transform splits of the form 'var OP threshold' into 'var*1.0 OP threshold'
    # to make sure SQL comparisons are not done in int.
    # Note that 'var OP threshold' should evaluate to false if var is null, and
    # SQL automatically provides this behavior.
    stopifnot(grepl(paste(kContinuousSplitTestOps, sep = "", collapse = '|'), split.str))
    for (op in kContinuousSplitTestOps) {
      split.str <- gsub(op, paste('*1.0', op), split.str)
    }
    return(split.str)
  }
  
  ConvertSplitTest <- function(split.str)
  {
    # Convert split according to type: 'categorical' or 'continuous'
    split.str <- gsub('== NA', 'IS NULL', split.str)
    split.str <- gsub('!= NA', 'IS NOT NULL', split.str)
    
    if (grepl(' IN \\( ', split.str)) {
      return(ConvertCategoricalSplitTest(split.str))
    } else if (grepl(paste(kContinuousSplitTestOps, sep = "", collapse = '|'), split.str))  {
      return(ConvertContinuousSplitTest(split.str))
    } else {
      return(split.str)
    }
  }
  
  ConvertLinearTerm <- function(var, x.trims.df)
  {
    # Transform linear terms into a SQL expression that accounts for "trims." 
    stopifnot(is.null(x.trims) || 
              length(which((colnames(x.trims.df) == c("vname", "min2keep", "max2keep", "mean")) == T)) == 4)
      
    # Set SQL template
    if (db.type == "SQLServer" || db.type == "Netezza" || db.type == "HiveQL") {
      SQL.TMPL <- "CASE WHEN _VAR_ IS NULL THEN _MEAN_ ELSE CASE WHEN _VAR_ < _MIN_ THEN _MIN_ WHEN _VAR_ > _MAX_ THEN _MAX_ ELSE _VAR_ END END"
    } else if (db.type == "MySQL") {
      SQL.TMPL <- "IF(_VAR_ IS NULL, _MEAN_, LEAST(_MAX_, GREATEST(_VAR_, _MIN_)))"
    } else {
      error(logger, paste("ConvertLinearTerm: Unknown db.type: ",  db.type))
    }

    # Instantiate template, if appropriate
    if ( is.null(x.trims) ) {
      # Simply return var name
      return(var)  
    } else {
      # Instantiate template with <min, mean, max>
      iRow <- grep(paste("^", var, "$", sep=""), x.trims.df$vname, perl=T)
      if ( length(iRow) == 1 ) {
        if (!is.null(x.trims.df$min2keep[iRow]) && !is.null(x.trims.df$max2keep[iRow]) &&
            !is.null(x.trims.df$mean[iRow])) {
          sql.str <- gsub("_VAR_", var, SQL.TMPL)
          sql.str <- gsub("_MIN_", x.trims.df$min2keep[iRow], sql.str)
          sql.str <- gsub("_MEAN_", x.trims.df$mean[iRow], sql.str)
          sql.str <- gsub("_MAX_", x.trims.df$max2keep[iRow], sql.str)
          return(sql.str)     
        } else {
          error(logger, paste("ConvertLinearTerm: Missing trim info for: ", var))
        }
      } else {
        error(logger, paste("ConvertLinearTerm: Didn't find: ", var, "in trim list"))
      }
    }
  }
  
  # -----------------------------------------------------------------------
  nTerms <- length(terms)
  if ( nTerms == 0 ) {
    error(logger, "ConvertTermsToSQL: 'terms' must not be empty")
  }
  
  # Were we given data to translate categorical split levels?
  x.levels <- NULL
  x.levels.lowcount <- NULL
  if (nchar(x.levels.fname) > 0) {
    x.levels <- ReadLevels(x.levels.fname)
    if (nchar(x.levels.lowcount.fname) > 0 && file.exists(x.levels.lowcount.fname) ) {
      x.levels.lowcount <- as.data.frame(do.call("rbind", ReadLevels(x.levels.lowcount.fname)))
    }
  }

  
  # Allocate return data-frame
  out.df <- data.frame(type = rep(NA, nTerms), coeff = rep(NA, nTerms), def = rep(NA, nTerms))
  
  # Process one model term at a time according to type: linear vs rule of splits
  for ( iTerm in 1:nTerms ) {
    term <- terms[[iTerm]]
    out.df$type[iTerm] <- term$type
    out.df$coeff[iTerm] <- term$coeff
    if ( term$type == kRuleTypeLinear ) {
      termStr <- ConvertLinearTerm(term$var, x.trims)
      out.df$def[iTerm] <- termStr
    }
    else if ( term$type == kRuleTypeSplit ) {
      termStr <- SplitRule2Char(term, x.levels, x.levels.lowcount)
      # Join term's splits with an AND
      termStr.splits <- strsplit(termStr, ' AND ')[[1]]
      # Transform any NA test within each split
      out.df$def[iTerm] <- paste(lapply(termStr.splits, ConvertSplitTest), sep="", collapse = " AND ")
    } else {
      error(logger, paste("ConvertTermsToSQL: unknown term type: ", term$type))
    }
  }
  return(out.df)
}

GetSQLRuleWrapper <- function(db.type)
{
  # Returns SQL-specific rule "wrapper" -- e.g., IF(rule, 1, 0) 
  stopifnot(db.type %in% c("SQLServer", "MySQL", "Netezza", "HiveQL"))

  if (db.type == "SQLServer" || db.type == "Netezza" || db.type == "HiveQL") {
    term.sql.head <- "CASE WHEN"
    term.sql.tail <- "THEN 1 ELSE 0 END"
  } else if (db.type == "MySQL") {
    term.sql.head <- "IF("
    term.sql.tail <- ",1,0)" 
  } 
  return(list(head = term.sql.head, tail = term.sql.tail))
}

AppendCoeffSQLWrapper <- function(term, term.sql.head, term.sql.tail)
  # Returns SQL version of c*rule(x) or c*x_j 
{     
  if (term['type'] == kRuleTypeLinear) {
    rule.sql.str <- paste(term['coeff'], "*", term['def'], sep="")
  } else if ( term['type'] == kRuleTypeSplit ) {
    rule.sql.str <- paste(term['coeff'], "*", term.sql.head, "(", term['def'], ")", term.sql.tail, sep="")
  } else {
    error(logger, paste("AppendCoeffSQLWrapper: unknown rule type: ", type))
  }
  return(rule.sql.str)
}

ApplySQLWrapper <- function(term, term.sql.head, term.sql.tail)
  # Returns SQL version of rule(x) or x_j 
{     
  if (term['type'] == kRuleTypeLinear) {
    rule.sql.str <- paste("1.0*", term['def'], sep="")
  } else if ( term['type'] == kRuleTypeSplit ) {
    rule.sql.str <- paste("1.0*", term.sql.head, "(", term['def'], ")", term.sql.tail, sep="")
  } else {
    error(logger, paste("ApplySQLWrapper: unknown rule type: ", type))
  }
  return(rule.sql.str)
}
  
BuildScoringClause <- function(terms.sql.df, db.type, c0)
{
  # Concatenates SQL-like version of model terms into a single scoring expression -- i.e., 
  # the SQL that computes c0 + c1*rule1(x) + c2*x_j +...
  #
  # Args:
  #   terms.sql.df : data-frame with tuples <type, coeff, def> where def is the term
  #                  definition already converted into a SQL-compatible string
  #        db.type : SQL dialect to use
  # Returns:
  #        Scoring SQL clause
  stopifnot(class(terms.sql.df) == "data.frame")
  stopifnot(length(which((names(terms.sql.df) == c("type", "coeff", "def"))==T)) == 3)
  
  # Set SQL-specific rule "wrapper"
  term.sql.wrapper <- GetSQLRuleWrapper(db.type)
  
  # Append coefficient and SQL wrapper to each term... concatenate all terms with "+"
  score.str <- paste(apply(terms.sql.df, 1, AppendCoeffSQLWrapper, term.sql.wrapper$head, term.sql.wrapper$tail), 
                     sep = "", collapse = " +\n")
                 
  # Add intercept to scoring string
  score.str <- paste(c0, score.str, sep = " +\n")
  return(score.str)               
}

BuildScoringClauseNoCoeff <- function(terms.sql.df, db.type)
{
  # Like BuildScoringClause() but without the coefficients -- i.e., constructs the SQL that computes
  # rule1(x) + rule3(x) + ... Primarily used for debugging purposes.
  #
  # Args:
  #   terms.sql.df : data-frame with tuples <type, coeff, def> where def is the term
  #                  definition already converted into a SQL-compatible string
  #        db.type : SQL dialect to use
  # Returns:
  #        Scoring SQL clause as sum of indicators.
  stopifnot(class(terms.sql.df) == "data.frame")
  stopifnot(length(which((names(terms.sql.df) == c("type", "coeff", "def"))==T)) == 3)

  # Set SQL-specific rule "wrapper"
  term.sql.wrapper <- GetSQLRuleWrapper(db.type)
  
  # Append coefficient and SQL wrapper to each term... concatenate all terms with "+"
  score.str <- paste(apply(terms.sql.df, 1, ApplySQLWrapper, term.sql.wrapper$head, term.sql.wrapper$tail), 
                     sep = "", collapse = " +\n")
  # Add 0.0 intercept to scoring string -- just because java model runner expects it
  score.str <- paste(0.0, score.str, sep = " +\n")
  return(score.str)               
}

BuildRulesOnlyClause <- function(terms.sql.df, db.type)
{
  # Builds a SQL clause for filling the individual table columns t_i, where t_i refers
  # to the i-th term in the model (a term can be either a rule or a winsorized numeric
  # predictor). This might be useful to study the "firing" pattern of the rules in a
  # new data set -- i.e., drift detection.
  #
  # Args:
  #   terms.sql.df : data-frame with tuples <type, coeff, def> where def is the term
  #                  definition already converted into a SQL-compatible string
  #        db.type : SQL dialect to use
  # Returns:
  #        Rules' SQL clause
  stopifnot(class(terms.sql.df) == "data.frame")
  stopifnot(length(which((names(terms.sql.df) == c("type", "coeff", "def"))==T)) == 3)
  stopifnot(db.type %in% c("SQLServer", "MySQL", "Netezza", "HiveQL"))
  
  # Set SQL-specific rule "wrapper"
  term.sql.wrapper <- GetSQLRuleWrapper(db.type)
  
  # Apply SQL wrapper to each rule term... concatenate all terms with ","
  num.terms <- nrow(terms.sql.df)
  rules.str <- paste(apply(terms.sql.df, 1, ApplySQLWrapper, term.sql.wrapper$head, term.sql.wrapper$tail), 
                     " t", 1:num.terms, sep = "", collapse = ",\n")
  return(rules.str)               
}

BuildRulesCoeffClause <- function(terms.sql.df, db.type, c0)
{
  # Like BuildRulesOnlyClause() but including coefficients.
  stopifnot(class(terms.sql.df) == "data.frame")
  stopifnot(length(which((names(terms.sql.df) == c("type", "coeff", "def"))==T)) == 3)
  
  # Set SQL-specific rule "wrapper"
  term.sql.wrapper <- GetSQLRuleWrapper(db.type)
  
  # Append coefficient and SQL wrapper to each term... concatenate all terms with ","
  num.terms <- nrow(terms.sql.df)
  score.str <- paste(apply(terms.sql.df, 1, AppendCoeffSQLWrapper, term.sql.wrapper$head, term.sql.wrapper$tail), 
                     " t", 1:num.terms, sep = "", collapse = ",\n")
                 
  # Add intercept to scoring string
  score.str <- paste(c0, score.str, sep = " t0,\n")
  return(score.str)               
}

BuildTermSumSQLExpression <- function(last.term, n.terms, max.sql.length, term.prefix = "t")
{
  # Returns a string of the form "t_last.term + t_(last.term + 1) +...+ t_n.terms"
  # truncated so as not to exceed max.sql.length in length.
  stopifnot(n.terms >= last.term)
  out.str <- paste(term.prefix, last.term:n.terms, sep="", collapse="+")
  if (nchar(out.str) > max.sql.length) {
    out.str <- substr(out.str, 1, max.sql.length)
    stopifnot(length(grep('\\+', out.str)) > 0)
    while (substr(out.str, nchar(out.str), nchar(out.str)) != '+') {
        out.str <- substr(out.str, 1, nchar(out.str)-1)
    }
    out.str <- substr(out.str, 1, nchar(out.str)-1)
  }
  return(out.str) 
}

BuildRulesCoeffScoringClause <- function(db.type, n.terms, max.sql.length)
{
  # The SQL expression generated by BuildScoringClause(), c0 + c1*r1(x) + ..., can
  # result in an "expression too complex" error for some SQL variants. In this case,
  # scoring can be achieved by using BuildRulesCoeffClause() instead, followed by
  # a score = t_0 + t_1 +... operation. If there are too many terms, however, this
  # simple summing expression also needs to be split.
  # Args:
  #            db.type : SQL dialect to use
  #            n.terms : number of terms to add
  #    max.sql.length : max sql expression length (in number of characters)
  # Returns: 
  #     scoring sql expression of the form:
  #               select score = s1 + s2 + s3 + ...
  #                 from (
  #                   select
  #                      s1 = t_1 + t_2 + t_3 + ... 
  #                     ,s2 = t_j + t_j+1 + ...
  #                      ...
  #                   from RulesCoeff Table
  #                 );
  stopifnot(db.type %in% c("SQLServer", "MySQL", "Netezza", "HiveQL"))

  AppendScoringSQLWrapper <- function(partial.sum.str, partial.sum.i, db.type,
                                      partial.sum.varname = "s")
  {
    # Returns SQL version of s_i = t_j + t_(j+1) + t_(j+2) + ...
    stopifnot(partial.sum.i >= 1)
    if (db.type == "MySQL" || db.type == "Netezza" || db.type == "HiveQL") {
      sql.str <- paste(partial.sum.str, "AS", paste0("s", partial.sum.i))
    } else if (db.type == "SQLServer") {
      sql.str <- paste(paste0(partial.sum.varname, partial.sum.i), "=", partial.sum.str)
    } 
  }

  # Build "s_i = t_j + t_j+1 + ..." expressions
  partial.sum.strs <- list()
  last.term <- 0
  repeat {
    sum.str <- BuildTermSumSQLExpression(last.term, n.terms, max.sql.length)
    partial.sum.strs <- c(partial.sum.strs, sum.str)
    n.terms.used <- length(which(strsplit(sum.str, "")[[1]] == "+")) + 1
    last.term <- last.term + n.terms.used
    if(last.term > n.terms) break() 
  }
  partial.sum.sql <- mapply(FUN=AppendScoringSQLWrapper, partial.sum.strs, partial.sum.i=1:length(partial.sum.strs),
                            db.type=db.type)
  partial.sum.sql <- paste(partial.sum.sql, collapse=",\n")

  # Build "score = s1 + ..." expression
  score.sum.sql <- BuildTermSumSQLExpression(1, length(partial.sum.strs), max.sql.length=255, term.prefix="s")
  
  #cat(partial.sum.sql)
  #cat("\n", score.sum.sql, "\n")  

  # Return both expressions together
  return(list(score.sum.sql = score.sum.sql, partial.sum.sql = partial.sum.sql))
}

BuildLCLClause <- function(model.path, levels.fname, out.path, out.fname, db.type)
{
  # When handling the lowcount levels in the data preparation step, we need to build a a sql clause,   
  # which is like case when var in (level1, level2, ...) then var else '_LowCountLevels_' end as var...
  # This function build this sql clause, and output to the file outfname_lowcount.
  tmp = ReadLevels(paste(model.path,levels.fname,sep="/"))   
  if (any(grepl("_LowCountLevels_",tmp))) {
  dotPos <- regexpr("\\.[^\\.]*$", out.fname)
  out.fname_lcl <- paste0(substr(out.fname,1,dotPos[1]-1),"_lowcount",".",substr(out.fname,dotPos[1]+1,nchar(out.fname)))
  
  factorChanged = ""
  varUnchanged = ""
  for(i in 1:length(tmp)){
      var = tmp[[i]]$var
      l = tmp[[i]]$levels
      valueList = paste(paste("'",l[2:length(l)], "'",sep=""), collapse = ",")
      if(grepl("_LowCountLevels_", tmp[[i]])[2]){
          if (db.type == "Netezza" || db.type == "SQLServer" || db.type == "HiveQL") {
              # Find the maximum length of all levels of categorical variable, default the maximum lenghth to be 25
              MaxNchar=25
              for (j in 2:length(l)) {
                  if (nchar(l[j]) > MaxNchar)
                      MaxNchar = nchar(l[j])
              } 
              # Do the data transforming
              tmpStr = sprintf("case when %s in (%s) then cast(%s as varchar(%s)) else '_LowCountLevels_' end as %s", var, valueList, var, MaxNchar, var)
              factorChanged = sprintf("%s,\n%s", factorChanged, tmpStr)
          } else if (db.type == "MySQL") {
              print("not implement currently")
          } else {
              print(paste(db.type,"is not a supported SQL dialet"))
          }
      } else {
          varUnchanged = sprintf("%s%s,", varUnchanged, var)
      }
  }
  factorChanged = substr(factorChanged, start=2, stop=nchar(factorChanged))
  
  query = sprintf("%s %s 
  ", varUnchanged, factorChanged)
  
  cat(query, file=paste(out.path, out.fname_lcl, sep="/"))
  }
}

ExportModel2SQL <- function(rego_Rules, model.path, out.path = model.path, levels.fname = "xtrain_levels.txt", out.fname = "rules_forSQL.txt", 
                            merge.dups = FALSE, expand.lcl.mode = 1,
                            export.type = "score", db.type = "SQLServer", max.sql.length = 500, x.trims = NULL) 
{
  # Generates a SQL expression corresponding to the scoring function defined by a
  # given RuleFit model.
  #
  # Args:
  #      model.path : path to RuleFit model exported files
  #        out.path : where SQL output file will be written
  #    levels.fname : levels file name (from training phase)
  #       out.fname : ouput file name 
  #      merge.dups : should duplicate terms be "merged"?
  # expand.lcl.mode : how to handle low-count level expansion
  #     export.type : one of {"score", "rulesonly", "rulesscore", "rulescoeff"}
  #         db.type : SQL dialect to use
  # max.sql.length : max sql expression length (in number of characters)
  #
  # Returns: 
  #     None.
  stopifnot(is.character(model.path))
  stopifnot(is.character(out.path))
  stopifnot(export.type %in% c("score", "rulesonly", "rulesscore", "rulescoeff"))
  
  # Read model definition -- combination of rules and linear terms
  terms <- rego_Rules
  
  # Merge "duplicate" terms? (if any) 
  # Already Done this in Python!
  # if (merge.dups) {
  #   terms <- MergeDuplicateTerms(terms)
  # }
  
  # Get SQL-compatible version of terms
  terms.df <- ConvertTermsToSQL(terms, db.type, x.levels.fname = file.path(model.path, kMod.x.levels.fname),
      x.levels.lowcount.fname = ifelse(expand.lcl.mode == 1, file.path(model.path, kMod.x.levels.lowcount.fname), ""),
      x.trims = x.trims)
  
  # Get intercept estimate
  if (file.exists(file.path(model.path, kMod.intercept.fname))) {
    c0 <- as.numeric(scan(file.path(model.path, kMod.intercept.fname), what='', quiet=T))
    # dbg(logger, paste("ExportModel2SQL: c0 =", c0))
  } else {
    error(logger, paste("ExportModel2SQL: couldn't find file:", file.path(model.path, kMod.intercept.fname)))
  }
  
  if (export.type == "score") {                          
    # Concatenate transformed terms into a scoring SQL clause
    sql.str <- BuildScoringClause(terms.df, db.type, c0)
  } else if (export.type == "rulesonly") {
    # Build SQL clause that creates one column per term (w/o coeff)
    sql.str <- BuildRulesOnlyClause(terms.df, db.type)
  } else if (export.type == "rulesscore") {
    # Build SQL clause that computes score based on adding indicator functions only (wo coeff)
    sql.str <- BuildScoringClauseNoCoeff(terms.df, db.type)
  } else {
    # Build SQL clause that creates one column per term (w coeff)
    stopifnot(export.type == "rulescoeff")
    sql.str <- BuildRulesCoeffClause(terms.df, db.type, c0)
    # ... and also the clause that adds the terms up
    score.str <- BuildRulesCoeffScoringClause(db.type, n.terms = nrow(terms.df), max.sql.length)
  }
  
  # Write out SQL clause(s) 
  sink(file.path(out.path, out.fname))
  cat(sql.str, "\n")
  sink()
  if (export.type == "rulescoeff") {
    dotPos <- regexpr("\\.[^\\.]*$", out.fname)
    out.fname1 <- paste0(substr(out.fname,1,dotPos[1]-1),"_part1",".",substr(out.fname,dotPos[1]+1,nchar(out.fname)))
    out.fname2 <- paste0(substr(out.fname,1,dotPos[1]-1),"_part2",".",substr(out.fname,dotPos[1]+1,nchar(out.fname)))
    sink(file.path(out.path, out.fname1))
    cat("\n", score.str$score.sum.sql, "\n")
    sink()
    sink(file.path(out.path, out.fname2))
    cat("\n", score.str$partial.sum.sql, "\n")
    sink()
  }

  # Low-count level expansion needed?
  if (expand.lcl.mode == 2) { 
    BuildLCLClause(model.path, levels.fname, out.path, out.fname, db.type)
  }
}
